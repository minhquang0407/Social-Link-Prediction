import sys
import os
import itertools
import json
import torch
import torch.nn.functional as F
import pandas as pd
import numpy as np
from tqdm import tqdm
from sklearn.metrics import roc_auc_score

# PyG Imports
from torch_geometric.loader import LinkNeighborLoader
from torch_geometric.nn import to_hetero
import torch_geometric.transforms as T
from torch_geometric.data import HeteroData

# Project Imports
from config.settings import (
    GRAPH_PATH, MODEL_PATH, PYG_DATA_PATH, MAPPING_PATH,
    CLEAN_DATA_PATH, TRAINING_HISTORY_PATH, BATCH_SIZE
)
from infrastructure.repositories.feature_repo import PyGDataRepository
from core.ai.gnn_architecture import GraphSAGE
from core.ai.data_processor import GraphDataProcessor


# --- 1. C√ÅC H√ÄM TI·ªÜN √çCH X·ª¨ L√ù DATA ---

def sanitize_hetero_data(data):
    """
    X√≥a c√°c lo·∫°i c·∫°nh r·ªóng ƒë·ªÉ tr√°nh l·ªói khi ch·∫°y Loader.
    """
    print("üßπ ƒêang d·ªçn d·∫πp c√°c lo·∫°i c·∫°nh r·ªóng...")
    # TODO 1: Duy·ªát qua data.edge_types.
    # Ki·ªÉm tra xem edge_index c√≥ t·ªìn t·∫°i ho·∫∑c c√≥ r·ªóng kh√¥ng.
    # N·∫øu r·ªóng th√¨ x√≥a lo·∫°i c·∫°nh ƒë√≥ kh·ªèi data (d√πng del data[et]).
    pass
    return data


def get_unified_edge_index(data, src_node_type='person', dst_node_type='person'):
    """
    G·ªôp t·∫•t c·∫£ c√°c lo·∫°i c·∫°nh n·ªëi gi·ªØa Person-Person l·∫°i th√†nh m·ªôt 'Si√™u c·∫°nh'
    ƒë·ªÉ l√†m nh√£n hu·∫•n luy·ªán (Supervision Target).
    """
    print(f"üîó ƒêang t·ªïng h·ª£p c√°c c·∫°nh n·ªëi gi·ªØa '{src_node_type}' v√† '{dst_node_type}':")
    
    # TODO 2: Duy·ªát qua data.edge_types.
    # 1. Ch·ªâ l·∫•y c·∫°nh n·ªëi src_node_type v√† dst_node_type.
    # 2. B·ªè qua c√°c c·∫°nh ngh·ªãch ƒë·∫£o (b·∫Øt ƒë·∫ßu b·∫±ng 'rev_') ƒë·ªÉ tr√°nh tr√πng l·∫∑p.
    # 3. Thu th·∫≠p edge_index v√†o m·ªôt list.
    
    # TODO 3: N·ªëi (Concat) t·∫•t c·∫£ edge_index l·∫°i theo chi·ªÅu ngang (dim=1).
    # TODO 4: L·ªçc b·ªè c√°c c·∫°nh tr√πng l·∫∑p (d√πng torch.unique).
    
    # Return v·ªÅ super_edge_index
    return torch.empty(2, 0) # Placeholder


def get_or_prepare_data():
    """T·∫£i v√† chu·∫©n b·ªã d·ªØ li·ªáu (Undirected + Sanitize)."""
    feature_repo = PyGDataRepository(PYG_DATA_PATH, MAPPING_PATH)
    data, mapping = feature_repo.load_data()

    if data is None:
        print("‚ö†Ô∏è Ch∆∞a c√≥ d·ªØ li·ªáu PyG. Vui l√≤ng ch·∫°y ETL tr∆∞·ªõc!")
        return None

    # TODO 5: Th·ª±c hi·ªán quy tr√¨nh l√†m s·∫°ch v√† chuy·ªÉn ƒë·ªïi ƒë·ªì th·ªã:
    # 1. G·ªçi sanitize_hetero_data l·∫ßn 1.
    # 2. Chuy·ªÉn ƒë·ªì th·ªã sang v√¥ h∆∞·ªõng (d√πng T.ToUndirected()).
    # 3. G·ªçi sanitize_hetero_data l·∫ßn 2 (ƒë·ªÉ d·ªçn r√°c do ToUndirected sinh ra).

    return data


# --- 2. C√ÅC H√ÄM TRAIN & EVAL ---

def train_epoch(model, loader, optimizer, device, target_edge_type):
    """Ch·∫°y 1 epoch hu·∫•n luy·ªán."""
    model.train()
    total_loss = 0
    total_examples = 0

    for batch in tqdm(loader, desc="Training", leave=False):
        batch = batch.to(device)

        # TODO 6: Quan tr·ªçng - √âp ki·ªÉu d·ªØ li·ªáu (Data Type Casting)
        # Ki·ªÉm tra batch.x_dict, n·∫øu l√† Float16 th√¨ √©p v·ªÅ Float32 ƒë·ªÉ tr√°nh l·ªói matmul.

        optimizer.zero_grad()

        # TODO 7: Forward Pass
        # 1. ƒê∆∞a d·ªØ li·ªáu qua model ƒë·ªÉ l·∫•y z_dict (embedding).
        # 2. L·∫•y edge_label_index v√† edge_label t·ª´ batch[target_edge_type].
        
        # TODO 8: Decode (T√≠nh ƒëi·ªÉm t∆∞∆°ng ƒë·ªìng)
        # L·∫•y embedding c·ªßa node ngu·ªìn v√† node ƒë√≠ch, th·ª±c hi·ªán Dot Product.

        # TODO 9: T√≠nh Loss v√† Backprop
        # D√πng binary_cross_entropy_with_logits.
        # G·ªçi backward() v√† optimizer.step().

        # C·∫≠p nh·∫≠t total_loss
        pass

    return total_loss / (total_examples + 1e-9)


@torch.no_grad()
def evaluate(model, loader, device, target_edge_type):
    """ƒê√°nh gi√° m√¥ h√¨nh."""
    model.eval()
    preds = []
    ground_truths = []

    for batch in tqdm(loader, desc="Evaluating", leave=False):
        batch = batch.to(device)

        # TODO 10: √âp ki·ªÉu d·ªØ li·ªáu v·ªÅ Float32 (t∆∞∆°ng t·ª± train_epoch).

        # TODO 11: Forward Pass v√† Decode
        # T∆∞∆°ng t·ª± train_epoch, nh∆∞ng KH√îNG t√≠nh loss, KH√îNG backprop.
        # L∆∞u √Ω: K·∫øt qu·∫£ output c·∫ßn qua h√†m .sigmoid() ƒë·ªÉ v·ªÅ x√°c su·∫•t [0, 1].

        # Append k·∫øt qu·∫£ v√†o preds v√† ground_truths
        pass

    # TODO 12: T√≠nh ROC AUC Score d√πng sklearn
    return 0.0 # Placeholder


# --- 3. CHI·∫æN L∆Ø·ª¢C CH·∫†Y ---

def train_one_config(data, config, device, final_mode=False):
    """Hu·∫•n luy·ªán v·ªõi 1 c·∫•u h√¨nh c·ª• th·ªÉ."""
    hidden_dim = config['hidden_dim']
    lr = config['lr']
    epochs = config['epochs']

    # --- CHU·∫®N B·ªä D·ªÆ LI·ªÜU ---
    # TODO 13: G·ªçi h√†m get_unified_edge_index ƒë·ªÉ t·∫°o 'Si√™u c·∫°nh' cho vi·ªác training.
    target_edge_type = ('person', 'super_link', 'person')

    # TODO 14: Chia d·ªØ li·ªáu (Split Train/Val)
    # N·∫øu final_mode=True: D√πng to√†n b·ªô si√™u c·∫°nh ƒë·ªÉ train.
    # N·∫øu final_mode=False: Chia 80% train, 20% val (d√πng torch.randperm).

    # TODO 15: Kh·ªüi t·∫°o LinkNeighborLoader
    # - Train Loader: shuffle=True, neg_sampling_ratio=1.0
    # - Val Loader (n·∫øu c√≥): shuffle=False, neg_sampling_ratio=1.0
    # L∆∞u √Ω: edge_label_index tr·ªè v√†o ph·∫ßn data ƒë√£ split ·ªü tr√™n.

    # --- KH·ªûI T·∫†O MODEL ---
    # TODO 16: Kh·ªüi t·∫°o GraphSAGE v√† convert sang Hetero (to_hetero).
    # Input dim l·∫•y t·ª´ data['person'].x.shape[1].
    model = None 
    optimizer = None

    history = {"epoch": [], "loss": [], "val_auc": []}
    best_val_auc = 0
    best_model_state = None

    print(f"\nüöÄ B·∫Øt ƒë·∫ßu train (Hidden={hidden_dim}, LR={lr})...")

    # --- TRAINING LOOP ---
    for epoch in range(1, epochs + 1):
        # TODO 17: G·ªçi train_epoch
        loss = 0 # Placeholder
        
        # Log history
        history["epoch"].append(epoch)
        history["loss"].append(float(loss))

        log_msg = f"Epoch {epoch:03d} | Loss: {loss:.4f}"

        # TODO 18: N·∫øu c√≥ val_loader, g·ªçi evaluate
        # C·∫≠p nh·∫≠t best_val_auc v√† best_model_state n·∫øu k·∫øt qu·∫£ t·ªët h∆°n.
        
        print(log_msg)

    # X·ª≠ l√Ω final mode
    if final_mode:
        best_model_state = model.state_dict() if model else None
        # L∆∞u history ra file JSON
        pass

    return best_val_auc, best_model_state


def run_grid_search():
    """Ch·∫°y Grid Search v√† Final Training."""
    data = get_or_prepare_data()
    if data is None: return

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"üñ•Ô∏è Running on: {device}")

    # Grid Search Configs
    param_grid = {
        'hidden_dim': [64, 128],
        'lr': [0.01],
        'epochs': [10]
    }
    
    # T·∫°o combinations t·ª´ param_grid
    keys, values = zip(*param_grid.items())
    combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]

    best_auc = 0
    best_params = None

    # TODO 19: Grid Search Loop
    # Duy·ªát qua c√°c config trong combinations.
    # G·ªçi train_one_config v·ªõi final_mode=False.
    # So s√°nh v√† l∆∞u l·∫°i config t·ªët nh·∫•t (best_auc).

    print(f"\nü•á Best Params: {best_params} (AUC: {best_auc:.4f})")
    
    # TODO 20: Final Training
    # C·∫≠p nh·∫≠t epochs l√™n cao h∆°n (v√≠ d·ª• 50).
    # G·ªçi train_one_config v·ªõi final_mode=True d√πng best_params.
    # L∆∞u model (torch.save) v√†o MODEL_PATH.

if __name__ == "__main__":
    run_grid_search()
